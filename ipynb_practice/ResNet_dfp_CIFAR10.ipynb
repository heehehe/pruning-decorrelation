{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_resnet_dfp import *\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data_mean = (0.5, 0.5, 0.5)\n",
    "train_data_std = (0.5, 0.5, 0.5)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(train_data_mean, train_data_std)\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=256, shuffle=True, num_workers=4)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "classes = ('plane','car','bird','cat','deer','dog','frog','horse','ship','truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = {\n",
    "    '18':  (BasicBlock, [2, 2, 2, 2]),\n",
    "    '34':  (BasicBlock, [3, 4, 6, 3]),\n",
    "    '50':  (Bottleneck, [3, 4, 6, 3]),\n",
    "    '101': (Bottleneck, [3, 4, 23, 3]),\n",
    "    '152': (Bottleneck, [3, 8, 36, 3]),\n",
    "}\n",
    "cfgs_cifar = {\n",
    "    '20':  [3, 3, 3],\n",
    "    '32':  [5, 5, 5],\n",
    "    '44':  [7, 7, 7],\n",
    "    '56':  [9, 9, 9],\n",
    "    '110': [18, 18, 18],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_CIFAR(BasicBlock, cfgs_cifar['20'], 10)\n",
    "image_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.3,\n",
    "                        momentum=0.9, weight_decay=1e-4) #, nesterov=args.nesterov)\n",
    "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\heese\\Miniconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    30] loss: 2.232\n",
      "[1,    60] loss: 1.909\n",
      "[1,    90] loss: 1.773\n",
      "[1,   120] loss: 1.698\n",
      "[1,   150] loss: 1.629\n",
      "[1,   180] loss: 1.509\n",
      "[2,    30] loss: 1.424\n",
      "[2,    60] loss: 1.325\n",
      "[2,    90] loss: 1.287\n",
      "[2,   120] loss: 1.203\n",
      "[2,   150] loss: 1.151\n",
      "[2,   180] loss: 1.097\n",
      "[3,    30] loss: 1.065\n",
      "[3,    60] loss: 0.998\n",
      "[3,    90] loss: 0.947\n",
      "[3,   120] loss: 0.927\n",
      "[3,   150] loss: 0.921\n",
      "[3,   180] loss: 0.893\n",
      "[4,    30] loss: 0.842\n",
      "[4,    60] loss: 0.812\n",
      "[4,    90] loss: 0.763\n",
      "[4,   120] loss: 0.804\n",
      "[4,   150] loss: 0.777\n",
      "[4,   180] loss: 0.782\n",
      "[5,    30] loss: 0.715\n",
      "[5,    60] loss: 0.698\n",
      "[5,    90] loss: 0.682\n",
      "[5,   120] loss: 0.640\n",
      "[5,   150] loss: 0.674\n",
      "[5,   180] loss: 0.668\n",
      "[6,    30] loss: 0.608\n",
      "[6,    60] loss: 0.629\n",
      "[6,    90] loss: 0.621\n",
      "[6,   120] loss: 0.621\n",
      "[6,   150] loss: 0.611\n",
      "[6,   180] loss: 0.616\n",
      "[7,    30] loss: 0.556\n",
      "[7,    60] loss: 0.602\n",
      "[7,    90] loss: 0.577\n",
      "[7,   120] loss: 0.561\n",
      "[7,   150] loss: 0.571\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader))\n",
    "epochs = 10\n",
    "device = 'cpu'\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    lr_sche.step()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 30 == 29:    # print every 30 mini-batches\n",
    "            # value_tracker(loss_plt, torch.Tensor([running_loss/30]), torch.Tensor([i + epoch*len(trainloader) ]))\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 30))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    #Check Accuracy\n",
    "#     acc = acc_check(model, testloader, epoch, save=1)\n",
    "    # value_tracker(acc_plt, torch.Tensor([acc]), torch.Tensor([epoch]))\n",
    "    \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
